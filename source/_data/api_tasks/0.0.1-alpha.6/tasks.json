{
  "docs": {
    "headings": [
      {
        "name": "Image Classification",
        "description": "",
        "subheadings": [
          {
            "name": "Base model",
            "symbols": [
              {
                "docInfo": {
                  "heading": "Image Classification",
                  "subheading": "Base model"
                },
                "symbolName": "ImageClassifier",
                "documentation": "The base class for all ImageClassification task models.",
                "fileName": "#30",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_classification/common.ts#L30-L53",
                "methods": [
                  {
                    "docInfo": {
                      "heading": "Image Classification",
                      "subheading": "Base model"
                    },
                    "symbolName": "predict",
                    "paramStr": "(img, options?)",
                    "parameters": [
                      {
                        "name": "img",
                        "documentation": "The image-like element to run classification on.",
                        "type": "ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement",
                        "optional": false,
                        "isConfigParam": false
                      },
                      {
                        "name": "options",
                        "documentation": "Inference options. Different models have different\ninference options. See individual model for more details.",
                        "type": "IO",
                        "optional": true,
                        "isConfigParam": false
                      }
                    ],
                    "returnType": "Promise<ImageClassificationResult>",
                    "documentation": "Performs classification on the given image-like input, and returns\nresult.",
                    "fileName": "#43",
                    "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_classification/common.ts#L43-L45",
                    "isFunction": true,
                    "unpackedReturnTypes": [
                      {
                        "description": "`ImageClassificationResult`",
                        "symbol": "ImageClassificationResult"
                      },
                      {
                        "description": "`Class`",
                        "symbol": "Class"
                      }
                    ]
                  },
                  {
                    "docInfo": {
                      "heading": "Image Classification",
                      "subheading": "Base model"
                    },
                    "symbolName": "cleanUp",
                    "paramStr": "()",
                    "parameters": [],
                    "returnType": "void",
                    "documentation": "Cleans up resources if needed.",
                    "fileName": "#52",
                    "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_classification/common.ts#L52-L52",
                    "isFunction": true
                  }
                ],
                "isClass": true,
                "inheritsFrom": "TaskModel"
              }
            ]
          },
          {
            "name": "Models",
            "symbols": [
              {
                "docInfo": {
                  "heading": "Image Classification",
                  "subheading": "Models"
                },
                "symbolName": "ICCustomModelTFLite",
                "documentation": "A custom TFLite image classification model loaded from a model url or\nan `ArrayBuffer` in memory.\n\nThe underlying image classifier is built on top of the [TFLite Task\nLibrary](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\nAs a result, the custom model needs to meet the [metadata\nrequirements](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier#model_compatibility_requirements).\n\nUsage:\n\n```js\n// Load the model from a custom url with other options (optional).\nconst model = await tfTask.ImageClassification.CustomModel.TFLite.load({\n   model:\n'https://tfhub.dev/google/lite-model/aiy/vision/classifier/plants_V1/3',\n});\n\n// Run inference on an image.\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result.classes);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ImageClassifier` for the `predict` and `cleanUp` method.",
                "fileName": "#111",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_classification/custom_model_tflite.ts#L111-L112",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ImageClassifierTFLite",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "ICCustomModelTFLiteLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "ICCustomModelTFLiteInferenceOptions"
                  }
                ]
              },
              {
                "docInfo": {
                  "heading": "Image Classification",
                  "subheading": "Models"
                },
                "symbolName": "MobilenetTFJS",
                "documentation": "Pre-trained TFJS mobilenet model.\n\nUsage:\n\n```js\n// Load the model with options (optional).\n//\n// By default, it uses mobilenet V1 with webgl backend. You can change them\n// in the options parameter of the `load` function (see below for docs).\nconst model = await tfTask.ImageClassification.Mobilenet.TFJS.load();\n\n// Run inference on an image with options (optional).\nconst img = document.querySelector('img');\nconst result = await model.predict(img, {topK: 5});\nconsole.log(result.classes);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ImageClassifier` for the `predict` and `cleanUp` method.",
                "fileName": "#96",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_classification/mobilenet_tfjs.ts#L96-L125",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ImageClassifier",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "MobilenetTFJSLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "MobilenetTFJSInferenceOptions"
                  }
                ]
              },
              {
                "docInfo": {
                  "heading": "Image Classification",
                  "subheading": "Models"
                },
                "symbolName": "MobilenetTFLite",
                "documentation": "Pre-trained TFLite mobilenet image classification model.\n\nUsage:\n\n```js\n// Load the model with options (optional).\n//\n// By default, it uses mobilenet V1. You can change it in the options\n// parameter of the `load` function (see below for docs).\nconst model = await tfTask.ImageClassification.Mobilenet.TFJS.load();\n\n// Run inference on an image.\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result.classes);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ImageClassifier` for the `predict` and `cleanUp` method.",
                "fileName": "#126",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_classification/mobilenet_tflite.ts#L126-L127",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ImageClassifierTFLite",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "MobilenetTFLiteLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "MobilenetTFLiteInferenceOptions"
                  }
                ]
              }
            ]
          }
        ]
      },
      {
        "name": "Image Segmentation",
        "description": "",
        "subheadings": [
          {
            "name": "Base model",
            "symbols": [
              {
                "docInfo": {
                  "heading": "Image Segmentation",
                  "subheading": "Base model"
                },
                "symbolName": "ImageSegmenter",
                "documentation": "The base class for all ImageSegmentation task models.",
                "fileName": "#29",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_segmentation/common.ts#L29-L52",
                "methods": [
                  {
                    "docInfo": {
                      "heading": "Image Segmentation",
                      "subheading": "Base model"
                    },
                    "symbolName": "predict",
                    "paramStr": "(img, options?)",
                    "parameters": [
                      {
                        "name": "img",
                        "documentation": "The image-like element to run segmentation on.",
                        "type": "ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement",
                        "optional": false,
                        "isConfigParam": false
                      },
                      {
                        "name": "options",
                        "documentation": "Inference options. Different models have different\ninference options. See individual model for more details.",
                        "type": "IO",
                        "optional": true,
                        "isConfigParam": false
                      }
                    ],
                    "returnType": "Promise<ImageSegmentationResult>",
                    "documentation": "Performs segmentation on the given image-like input, and returns\nresult.",
                    "fileName": "#42",
                    "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_segmentation/common.ts#L42-L44",
                    "isFunction": true,
                    "unpackedReturnTypes": [
                      {
                        "description": "`ImageSegmentationResult`",
                        "symbol": "ImageSegmentationResult"
                      },
                      {
                        "description": "`Legend`",
                        "symbol": "Legend"
                      },
                      {
                        "description": "`Color`",
                        "symbol": "Color"
                      }
                    ]
                  },
                  {
                    "docInfo": {
                      "heading": "Image Segmentation",
                      "subheading": "Base model"
                    },
                    "symbolName": "cleanUp",
                    "paramStr": "()",
                    "parameters": [],
                    "returnType": "void",
                    "documentation": "Cleans up resources if needed.",
                    "fileName": "#51",
                    "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_segmentation/common.ts#L51-L51",
                    "isFunction": true
                  }
                ],
                "isClass": true,
                "inheritsFrom": "TaskModel"
              }
            ]
          },
          {
            "name": "Models",
            "symbols": [
              {
                "docInfo": {
                  "heading": "Image Segmentation",
                  "subheading": "Models"
                },
                "symbolName": "ISCustomModelTFLite",
                "documentation": "A custom TFLite image segmentation model loaded from a model url or an\n`ArrayBuffer` in memory.\n\nThe underlying image segmenter is built on top of the [TFLite Task\nLibrary](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\nAs a result, the custom model needs to meet the [metadata\nrequirements](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_segmenter#model_compatibility_requirements).\n\nUsage:\n\n```js\n// Load the model from a custom url with other options (optional).\nconst model = await tfTask.ImageSemgentation.CustomModel.TFLite.load({\n   model:\n'https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/2?lite-format=tflite',\n});\n\n// Run inference on an image.\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ImageSegmenter` for the `predict` and `cleanUp` method.",
                "fileName": "#111",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_segmentation/custom_model_tflite.ts#L111-L112",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ImageSegmenterTFLite",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "ISCustomModelTFLiteLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "ISCustomModelTFLiteInferenceOptions"
                  }
                ]
              },
              {
                "docInfo": {
                  "heading": "Image Segmentation",
                  "subheading": "Models"
                },
                "symbolName": "DeeplabTFJS",
                "documentation": "Pre-trained TFJS depelab model.\n\nUsage:\n\n```js\n// Load the model with options (optional).\n//\n// By default, it uses base='pascal' and quantizationBytes=2 with webgl\n// backend. You can change them in the options parameter of the `load`\n// function (see below for docs).\nconst model = await tfTask.ImageSegmentation.Deeplab.TFJS.load();\n\n// Run inference on an image with options (optional).\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ImageSegmenter` for the `predict` and `cleanUp` method.",
                "fileName": "#104",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_segmentation/deeplab_tfjs.ts#L104-L143",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ImageSegmenter",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "DeeplabTFJSLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "DeeplabTFJSInferenceOptions"
                  }
                ]
              },
              {
                "docInfo": {
                  "heading": "Image Segmentation",
                  "subheading": "Models"
                },
                "symbolName": "DeeplabTFLite",
                "documentation": "Pre-trained TFLite deeplab image segmentation model.\n\nUsage:\n\n```js\n// Load the model with options (optional).\nconst model = await tfTask.ImageSegmentation.Deeplab.TFLite.load();\n\n// Run inference on an image.\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ImageSegmenter` for the `predict` and `cleanUp` method.",
                "fileName": "#92",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/image_segmentation/deeplab_tflite.ts#L92-L93",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ImageSegmenterTFLite",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "DeeplabTFLiteLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "DeeplabTFLiteInferenceOptions"
                  }
                ]
              }
            ]
          }
        ]
      },
      {
        "name": "Object Detection",
        "description": "",
        "subheadings": [
          {
            "name": "Base model",
            "symbols": [
              {
                "docInfo": {
                  "heading": "Object Detection",
                  "subheading": "Base model"
                },
                "symbolName": "ObjectDetector",
                "documentation": "The base class for all ObjectDetection task models.",
                "fileName": "#30",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/object_detection/common.ts#L30-L53",
                "methods": [
                  {
                    "docInfo": {
                      "heading": "Object Detection",
                      "subheading": "Base model"
                    },
                    "symbolName": "predict",
                    "paramStr": "(img, options?)",
                    "parameters": [
                      {
                        "name": "img",
                        "documentation": "The image-like element to detect objects on.",
                        "type": "ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement",
                        "optional": false,
                        "isConfigParam": false
                      },
                      {
                        "name": "options",
                        "documentation": "Inference options. Different models have different\ninference options. See individual model for more details.",
                        "type": "IO",
                        "optional": true,
                        "isConfigParam": false
                      }
                    ],
                    "returnType": "Promise<ObjectDetectionResult>",
                    "documentation": "Detects objects on the given image-like input, and returns result.",
                    "fileName": "#43",
                    "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/object_detection/common.ts#L43-L45",
                    "isFunction": true,
                    "unpackedReturnTypes": [
                      {
                        "description": "`ObjectDetectionResult`",
                        "symbol": "ObjectDetectionResult"
                      },
                      {
                        "description": "`DetectedObject`",
                        "symbol": "DetectedObject"
                      },
                      {
                        "description": "`BoundingBox`",
                        "symbol": "BoundingBox"
                      },
                      {
                        "description": "`Class`",
                        "symbol": "Class"
                      }
                    ]
                  },
                  {
                    "docInfo": {
                      "heading": "Object Detection",
                      "subheading": "Base model"
                    },
                    "symbolName": "cleanUp",
                    "paramStr": "()",
                    "parameters": [],
                    "returnType": "void",
                    "documentation": "Cleans up resources if needed.",
                    "fileName": "#52",
                    "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/object_detection/common.ts#L52-L52",
                    "isFunction": true
                  }
                ],
                "isClass": true,
                "inheritsFrom": "TaskModel"
              }
            ]
          },
          {
            "name": "Models",
            "symbols": [
              {
                "docInfo": {
                  "heading": "Object Detection",
                  "subheading": "Models"
                },
                "symbolName": "CocoSsdTFJS",
                "documentation": "Pre-trained TFJS coco-ssd model.\n\nUsage:\n\n```js\n// Load the model with options (optional).\n//\n// By default, it uses lite_mobilenet_v2 as the base model with webgl\n// backend. You can change them in the `options` parameter of the `load`\n// function (see below for docs).\nconst model = await tfTask.ObjectDetection.CocoSsd.TFJS.load();\n\n// Run detection on an image with options (optional).\nconst img = document.querySelector('img');\nconst result = await model.predict(img, {numMaxBoxes: 5});\nconsole.log(result.objects);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ObjectDetector` for the `predict` and `cleanUp` method.",
                "fileName": "#106",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/object_detection/cocossd_tfjs.ts#L106-L148",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ObjectDetector",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "CocoSsdTFJSLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "CocoSsdTFJSInferenceOptions"
                  }
                ]
              },
              {
                "docInfo": {
                  "heading": "Object Detection",
                  "subheading": "Models"
                },
                "symbolName": "CocoSsdTFLite",
                "documentation": "Pre-trained TFLite coco-ssd object detection model.\n\nUsage:\n\n```js\n// Load the model with options (optional).\nconst model = await tfTask.ObjectDetection.CocoSsd.TFLite.load();\n\n// Run inference on an image.\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result.objects);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ObjectDetector` for the `predict` and `cleanUp` method.",
                "fileName": "#92",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/object_detection/cocossd_tflite.ts#L92-L93",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ObjectDetectorTFLite",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "CocoSsdTFLiteLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "CocoSsdTFLiteInferenceOptions"
                  }
                ]
              },
              {
                "docInfo": {
                  "heading": "Object Detection",
                  "subheading": "Models"
                },
                "symbolName": "ODCustomModelTFLite",
                "documentation": "A custom TFLite object detection model loaded from a model url or an\n`ArrayBuffer` in memory.\n\nThe underlying object detector is built on top of the [TFLite Task\nLibrary](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\nAs a result, the custom model needs to meet the [metadata\nrequirements](https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector#model_compatibility_requirements).\n\nUsage:\n\n```js\n// Load the model from a custom url with other options (optional).\nconst model = await tfTask.ObjectDetection.CustomModel.TFLite.load({\n   model:\n'https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/metadata/2?lite-format=tflite',\n});\n\n// Run inference on an image.\nconst img = document.querySelector('img');\nconst result = await model.predict(img);\nconsole.log(result.objects);\n\n// Clean up.\nmodel.cleanUp();\n```\n\nRefer to `tfTask.ObjectDetector` for the `predict` and `cleanUp` method.",
                "fileName": "#111",
                "githubUrl": "https://github.com/tensorflow/tfjs-models/tree/tasks-v0.0.1-alpha.6/tasks/src/tasks/object_detection/custom_model_tflite.ts#L111-L112",
                "methods": [],
                "isClass": true,
                "inheritsFrom": "ObjectDetectorTFLite",
                "extraTypes": [
                  {
                    "description": "Options for `load`",
                    "symbol": "ODCustomModelTFLiteLoadingOptions"
                  },
                  {
                    "description": "Options for `predict`",
                    "symbol": "ODCustomModelTFLiteInferenceOptions"
                  }
                ]
              }
            ]
          }
        ]
      }
    ]
  },
  "docLinkAliases": {},
  "configInterfaceParamMap": {
    "TFJSModelCommonLoadingOption": [
      {
        "name": "backend",
        "type": "TFJSBackend",
        "documentation": "The backend to use to run TFJS models. Default to 'webgl'.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "TFLiteCustomModelCommonLoadingOption": [
      {
        "name": "model",
        "type": "string|ArrayBuffer",
        "documentation": "The model url, or the model content stored in an `ArrayBuffer`.\n\nYou can use TFLite model urls from `tfhub.dev` directly. For model\ncompatibility, see comments in the corresponding model class.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "Class": [
      {
        "name": "className",
        "type": "string",
        "documentation": "The name of the class.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "score",
        "type": "number",
        "documentation": "The score of the class.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "TaskModel": [
      {
        "name": "cleanUp",
        "type": "void",
        "documentation": "Cleans up resources if necessary.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "TaskModelMetadata": [
      {
        "name": "name",
        "type": "string",
        "documentation": "Human-readable model name.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "description",
        "type": "string",
        "documentation": "The model description. Can have simple HTML tags.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "resourceUrls",
        "type": "{[name: string]: string}",
        "documentation": "Resource urls (e.g. github page, docs, etc) indexed by names.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "runtime",
        "type": "Runtime",
        "documentation": "The model runtime.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "version",
        "type": "string",
        "documentation": "The model version.\n\nThis should be used to construct the main package url in the `packageUrls`\nfield below so that the package version matches the version specified here.\n\nTODO: allow users to dynamically specify which version to load.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "supportedTasks",
        "type": "Task[]",
        "documentation": "Tasks that the model supports.\n\nThis needs to match the location(s) of this model loader in the main index\nin all_tasks.ts file. A test will run to make sure of this.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ImageClassificationResult": [
      {
        "name": "classes",
        "type": "Class[]",
        "documentation": "All predicted classes.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ICCustomModelTFLiteLoadingOptions": [
      {
        "name": "model",
        "type": "string|ArrayBuffer",
        "documentation": "The model url, or the model content stored in an `ArrayBuffer`.\n\nYou can use TFLite model urls from `tfhub.dev` directly. For model\ncompatibility, see comments in the corresponding model class.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "maxResults",
        "type": "number",
        "documentation": "Maximum number of top scored results to return. If < 0, all results will\nbe returned. If 0, an invalid argument error is returned.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "scoreThreshold",
        "type": "number",
        "documentation": "Score threshold in [0,1), overrides the ones provided in the model metadata\n(if any). Results below this value are rejected.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "numThreads",
        "type": "number",
        "documentation": "The number of threads to be used for TFLite ops that support\nmulti-threading when running inference with CPU. num_threads should be\ngreater than 0 or equal to -1. Setting num_threads to -1 has the effect to\nlet TFLite runtime set the value.\n\nDefault to number of physical CPU cores, or -1 if WASM multi-threading is\nnot supported by user's browser.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ICCustomModelTFLiteInferenceOptions": [],
    "MobilenetTFJSLoadingOptions": [
      {
        "name": "backend",
        "type": "TFJSBackend",
        "documentation": "The backend to use to run TFJS models. Default to 'webgl'.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "MobilenetTFJSInferenceOptions": [
      {
        "name": "topK",
        "type": "number",
        "documentation": "Number of top classes to return.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "MobilenetTFLiteLoadingOptions": [
      {
        "name": "version",
        "type": "1|2",
        "documentation": "The MobileNet version number. Use 1 for MobileNetV1, and 2 for\nMobileNetV2. Defaults to 1.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "alpha",
        "type": "0.25|0.50|0.75|1.0",
        "documentation": "Controls the width of the network, trading accuracy for performance. A\nsmaller alpha decreases accuracy and increases performance. Defaults\nto 1.0.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "maxResults",
        "type": "number",
        "documentation": "Maximum number of top scored results to return. If < 0, all results will\nbe returned. If 0, an invalid argument error is returned.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "scoreThreshold",
        "type": "number",
        "documentation": "Score threshold in [0,1), overrides the ones provided in the model metadata\n(if any). Results below this value are rejected.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "numThreads",
        "type": "number",
        "documentation": "The number of threads to be used for TFLite ops that support\nmulti-threading when running inference with CPU. num_threads should be\ngreater than 0 or equal to -1. Setting num_threads to -1 has the effect to\nlet TFLite runtime set the value.\n\nDefault to number of physical CPU cores, or -1 if WASM multi-threading is\nnot supported by user's browser.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "MobilenetTFLiteInferenceOptions": [],
    "Legend": [],
    "Color": [
      {
        "name": "r",
        "type": "number",
        "documentation": "The red color component for the label, in the [0, 255] range.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "g",
        "type": "number",
        "documentation": "The green color component for the label, in the [0, 255] range.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "b",
        "type": "number",
        "documentation": "The blue color component for the label, in the [0, 255] range.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ImageSegmentationResult": [
      {
        "name": "legend",
        "type": "Legend",
        "documentation": "",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "width",
        "type": "number",
        "documentation": "The width of the returned segmentation map.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "height",
        "type": "number",
        "documentation": "The height of the returned segmentation map.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "segmentationMap",
        "type": "Uint8ClampedArray",
        "documentation": "The colored segmentation map as `Uint8ClampedArray` which can be\nfed into `ImageData` and mapped to a canvas.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ISCustomModelTFLiteLoadingOptions": [
      {
        "name": "model",
        "type": "string|ArrayBuffer",
        "documentation": "The model url, or the model content stored in an `ArrayBuffer`.\n\nYou can use TFLite model urls from `tfhub.dev` directly. For model\ncompatibility, see comments in the corresponding model class.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "outputType",
        "type": "OutputType",
        "documentation": "",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "numThreads",
        "type": "number",
        "documentation": "The number of threads to be used for TFLite ops that support\nmulti-threading when running inference with CPU. num_threads should be\ngreater than 0 or equal to -1. Setting num_threads to -1 has the effect to\nlet TFLite runtime set the value.\n\nDefault to number of physical CPU cores, or -1 if WASM multi-threading is\nnot supported by user's browser.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ISCustomModelTFLiteInferenceOptions": [],
    "DeeplabTFJSLoadingOptions": [
      {
        "name": "backend",
        "type": "'cpu'|'webgl'",
        "documentation": "The backend to use to run TFJS models. Default to 'webgl'.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "DeeplabTFJSInferenceOptions": [],
    "DeeplabTFLiteLoadingOptions": [
      {
        "name": "outputType",
        "type": "OutputType",
        "documentation": "",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "numThreads",
        "type": "number",
        "documentation": "The number of threads to be used for TFLite ops that support\nmulti-threading when running inference with CPU. num_threads should be\ngreater than 0 or equal to -1. Setting num_threads to -1 has the effect to\nlet TFLite runtime set the value.\n\nDefault to number of physical CPU cores, or -1 if WASM multi-threading is\nnot supported by user's browser.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "DeeplabTFLiteInferenceOptions": [],
    "ObjectDetectionResult": [
      {
        "name": "objects",
        "type": "DetectedObject[]",
        "documentation": "All detected objects.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "DetectedObject": [
      {
        "name": "boundingBox",
        "type": "BoundingBox",
        "documentation": "The bounding box of the object.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "className",
        "type": "string",
        "documentation": "The name of the class.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "score",
        "type": "number",
        "documentation": "The score of the class.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "BoundingBox": [
      {
        "name": "originX",
        "type": "number",
        "documentation": "The X coordinate of the top-left corner of the bounding box.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "originY",
        "type": "number",
        "documentation": "The Y coordinate of the top-left corner of the bounding box.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "width",
        "type": "number",
        "documentation": "The width of bounding box.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "height",
        "type": "number",
        "documentation": "The height of bounding box.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "CocoSsdTFJSLoadingOptions": [
      {
        "name": "backend",
        "type": "TFJSBackend",
        "documentation": "The backend to use to run TFJS models. Default to 'webgl'.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "CocoSsdTFJSInferenceOptions": [
      {
        "name": "maxNumBoxes",
        "type": "number",
        "documentation": "The maximum number of bounding boxes of detected objects. There can be\nmultiple objects of the same class, but at different locations. Defaults\nto 20.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "minScore",
        "type": "number",
        "documentation": "The minimum score of the returned bounding boxes of detected objects. Value\nbetween 0 and 1. Defaults to 0.5.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "CocoSsdTFLiteLoadingOptions": [
      {
        "name": "maxResults",
        "type": "number",
        "documentation": "Maximum number of top scored results to return. If < 0, all results will\nbe returned. If 0, an invalid argument error is returned.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "scoreThreshold",
        "type": "number",
        "documentation": "Score threshold in [0,1), overrides the ones provided in the model metadata\n(if any). Results below this value are rejected.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "numThreads",
        "type": "number",
        "documentation": "The number of threads to be used for TFLite ops that support\nmulti-threading when running inference with CPU. num_threads should be\ngreater than 0 or equal to -1. Setting num_threads to -1 has the effect to\nlet TFLite runtime set the value.\n\nDefault to number of physical CPU cores, or -1 if WASM multi-threading is\nnot supported by user's browser.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "CocoSsdTFLiteInferenceOptions": [],
    "ODCustomModelTFLiteLoadingOptions": [
      {
        "name": "model",
        "type": "string|ArrayBuffer",
        "documentation": "The model url, or the model content stored in an `ArrayBuffer`.\n\nYou can use TFLite model urls from `tfhub.dev` directly. For model\ncompatibility, see comments in the corresponding model class.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "maxResults",
        "type": "number",
        "documentation": "Maximum number of top scored results to return. If < 0, all results will\nbe returned. If 0, an invalid argument error is returned.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "scoreThreshold",
        "type": "number",
        "documentation": "Score threshold in [0,1), overrides the ones provided in the model metadata\n(if any). Results below this value are rejected.",
        "optional": false,
        "isConfigParam": true
      },
      {
        "name": "numThreads",
        "type": "number",
        "documentation": "The number of threads to be used for TFLite ops that support\nmulti-threading when running inference with CPU. num_threads should be\ngreater than 0 or equal to -1. Setting num_threads to -1 has the effect to\nlet TFLite runtime set the value.\n\nDefault to number of physical CPU cores, or -1 if WASM multi-threading is\nnot supported by user's browser.",
        "optional": false,
        "isConfigParam": true
      }
    ],
    "ODCustomModelTFLiteInferenceOptions": []
  },
  "inlineTypes": {
    "TFJSBackend": "'cpu'|'webgl'|'wasm'"
  },
  "docTypeAliases": {}
}