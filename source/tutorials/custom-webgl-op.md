---
title: custom-webgl-op
date: 2018-08-02 16:07:20
---

### Sections
---
* [Creating custom WebGL operations](#tutorial)
* [GLSL functions provided by Tensorflow.js](#stdlib)


# <a id="tutorial"></a>Creating custom WebGL operations

To define custom WebGL operations, all we have to do is create an object that implements `tf.webgl.GPGPUProgram`.

This interface is defined as:
```ts
interface GPGPUProgram {
  variableNames: string[];
  outputShape: number[];
  userCode: string;
  supportsBroadcasting?: boolean;
}
```

For a contrived example, lets implement an operation that computes `f(x) = x * x + x`.

The GLSL code for this would be:
```glsl
void main() {
    float x = getXAtOutCoords();
    float value = x * x + x;
    setOutput(value);
}
```

where `getXAtOutCoords` and `setOutput` are [provided by Tensorflow.js](#stdlib) to the shader.
Note that the main function is called for each value in the output tensor.


The full GPGPUProgram definition would be:
```js
const squareAndAddKernel = inputShape => ({
  variableNames: ['X'],
  outputShape: inputShape.slice(),
  userCode: `
    void main() {
        float x = getXAtOutCoords();
        float value = x * x + x;
        setOutput(value);
      }
  `
})
```

To run this op, you would use `tf.ENV.backend.compileAndRun(program: GPGPUProgram, inputs: tf.Tensor[]): tf.Tensor`. Note that this will be undefined if the backend isn't the webgl backend.

```js
const x = tf.tensor([1, 2, 3, 4]);
const program = squareAndAddKernel(x.shape);

const result = tf.ENV.backend.compileAndRun(program, [x]);
```

However, we probably also want to define the gradients for this op, so that gradients can be backpropagated through it.

To do this, we use [tf.customGrad](https://js.tensorflow.org/api/latest/#customGrad).

```js
const squareAndAddBackpropKernel = inputShape => ({
  variableNames: ['X'],
  outputShape: inputShape.slice(),
  userCode: `
    void main() {
      float x = getXAtOutCoords();
      float value = 2.0 * x + 1.0;
      setOutput(value);
    }
  `
});


const squareAndAdd = tf.customGrad(x => {
  const backend = tf.ENV.backend;
  const program = squareAndAddKernel(x.shape);
  const backpropProgram = squareAndAddBackpropKernel(x.shape);

  const value = backend.compileAndRun(program, [x]);

  const gradFunc = dy =>
      [backend.compileAndRun(backpropProgram, [x]).mul(dy)];
  return {value, gradFunc};
});
```

We can then use this as:

```js
const x = tf.tensor([1, 2, 3, 4]);

const value = squareAndAdd(x);

const grads = tf.grad(x => squareAndAdd(x));
const dx = grads(input);

// value == [2, 6, 12, 20]
// dx == [3, 5, 7, 9]
```

Or more concisely:

```js
const {value, grad} = tf.valueAndGrad(squareAndAdd)(x);
```

# <a id="stdlib"></a>GLSL functions generated by Tensorflow.js

Tensorflow.js generates functions you can use to read from the input tensors and write to the output tensor, as well as additional numeric utility functions. These are prepended to your code by the [Shader Compiler](https://github.com/tensorflow/tfjs-core/blob/master/src/kernels/webgl/shader_compiler.ts).

* `void setOutput(float value)`

  * Sets the output value for the coordinate where the fragment shader is run on (equivalent to `gl_FragCoord = vec4(value, 0.0, 0.0, 0.0)`).

* `indexType getOutputCoords()`

  * Where `indexType` is one of `int | ivec2 | ivec3 | ivec4 | ivec5 | ivec6`.

  * Returns an `int` if the output tensor is rank-0 or rank-1, otherwise returns an `ivecN` where N == rank. This is the coordinate of the cell in the output tensor this program will write to.


* Tensorflow.js generates GLSL functions to sample from the input tensors. These are of the form:

  ```glsl
    float get{VarName}AtOutCoords()

    float get{VarName}() // rank-0 input
    float get{VarName}(int x) // rank-1 input
    float get{VarName}(int x, int y) // rank-2 input
    float get{VarName}(int x, int y, int z) // rank-3 input
    float get{VarName}(int x, int y, int z, int w) // rank-4 input
    // continue as above for rank-5 & rank-6

    // For example, for rank-2 Tensor named x:
    // float getX(int x, int y)
  ```

  Where `VarName` is a variable name as defined in the `variableNames` array of your `GPGPUProgram` in **with the first letter captialised**.
  This means that for a variable named `matrix`, TF.js will generate `getMatrix`.

  Many of these functions are depended on the rank of the input tensors, so in your `GPGPUProgram` you'll often want to emit different code based on the ranks of the `inputShape`s.
  For instance, if `get{VarName}AtOutCoords()` didn't exist, we might have written `squareAndAddKernel` as:

  ```js
  const squareAndAddKernel = inputShape => ({
    const variableNames = ['X']
    const outputShape = inputShape.slice()
    const rank = outputShape.length

    const coordSnippets = ['',
        'coords',
        'coords.x, coords.y',
        'coords.x, coords.y, coords.z',
        'coords.x, coords.y, coords.z, coords.w']

    const coordType = rank < 2 ? 'int' : `ivec${rank}`

    const userCode = `
      void main() {
        ${coordType} coords = getOutputCoords();
        float x = getX(${coordSnippets[rank]});
        setOutput(x * x + x);
      }`

    return {variableNames, outputShape, userCode}
  })
  ```

  * `bool isNaN(float val)`

    * `true` if val is a `NaN`, otherwise false.

  * `int round(float value)`

    * Round `value` to the nearest integer.

  * `int imod(int x, int y)`

    * Same as `float mod(float x, float y)` but for ints, since GLSL doesn't provide us one.

  * `float random(float seed)`

    * Returns a pseudo-random number, based on Dave Hoskins's formula in https://www.shadertoy.com/view/4djSRW.

